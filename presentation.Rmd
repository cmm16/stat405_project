---
title: "Flight and Airport Analysis"
author: "Cole Morgan, Melinda Ding, Henry Creamer, Aaryan Jadhav, Caleigh Page (Group 10)"
date: "December 6, 2019"
output: ioslides_presentation
runtime: shiny
---

```{r setup, include=FALSE}
# runtime: shiny

knitr::opts_chunk$set(echo = FALSE)
```

```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE}
library(RSQLite)
library(ggplot2)
library(tidyverse)
library(grid)
library(gridBase)
library(gridExtra)
library(shiny)
library(dplyr)
library(jpeg)
library(prophet)
dcon <- dbConnect(SQLite(), dbname="C:/Users/bcard/Documents/SavedStuff/Stat405/group10.db")
```


## Introduction 

RESEARCH QUESTIONS

- What are the most popular airlines and destinations from IAH? 
- How have flight patterns out of IAH changed over time? 
- How does airport quality affect the number of flights and passengers going to an airport?


## Introduction 

METHODOLOGY 

- Gathered and cleaned data from 5 different data sources
- Explored the data 
- Created two killer plots to summarize findings

## {.flexbox .vcenter}
<div class="centered">
  <font size="8">Data Gathering and Preparation</font> 
</div>

## Data Set #1 
FLIGHT DATA 

- 2015-2018
- Dimensions: 6,287,635 x 21
- Source: Bureau of Transportation Statistics 
- Attributes: Year, month, day, day of the week, airline id, tail number, flight number, origin, origin city, dest, dest city, expected departure time, departure time, departure delay, arrival delay, cancelled (bool), carrier delay (bool), weather delay (bool)

## Data Set #2
PASSENGER DATA

- 2018
- Dimensions: 381,291 x 19
- Source: Bureau of Transportation Statistics 
- Attributes: seats, passengers, unique_carrier, origin, origin_city, origin_state, dest, dest_city, dest_state, aircraft_type, class (only passenger)

## Data Set #3
REVIEWS DATA

- 2015
- Dimensions: 17,721 x 21
- Source: https://www.airlinequality.com/
- Attributes: airport_name, link, title, author, author_country, date, content, experience_airport, date_visit, type_traveller, overall_rating, queing_rating, terminal_cleanliness_rating, terminal_seating_rating, food_beverages_rating, airport_shopping_rating, wifi_connectivity_rating, airport_staff_rating, recommended 

## Data Set #4 
SENTIMENT DATA

- First compiled a list of the top 2,000 words across all airport reviews 
- Scraped 10 synonyms for each word in the top 2,000 words from thesaurus.com
- Dimensions: 2,000 x 11
- Attributes: word, synonym1, synonym2, synonym3, synonym4, synonym5, synonym6, synonym7, synonym8, synonym9, synonym10

## Data Set #5
AIRLINE LOGO DATA

- First found the airlines that fly out of IAH 
- Scraped the airline logos from travelpayouts.com
- Attributes: 12 jpeg images



## {.flexbox .vcenter}
<div class="centered">
  <font size="8">Exploratory Data Analysis</font> 
</div>

## Top 20 Airport Destinations by Location
```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE}
res <- dbSendQuery(conn = dcon, "
SELECT ORIGIN, count(*) as c
FROM flights
GROUP BY ORIGIN 
ORDER BY c DESC")
topOutgoing <- dbFetch(res, -1)
txairports <- c("ABI", "AUS", "CRP", "DFW", "DAL", "ELP", "GRK", "IAH", "HOU", "LBB", "MAF", "SAT", "ACT", "SPS")
topOutTexas <- topOutgoing$ORIGIN[topOutgoing$ORIGIN %in% txairports]
top4Texas <- topOutTexas[1:4]
dbClearResult(res)
res <- dbSendQuery(conn = dcon, "
SELECT *
FROM flights
WHERE ORIGIN = 'IAH';")
iahFlights <- dbFetch(res, -1)
dbClearResult(res)

res <- dbSendQuery(conn = dcon, "
SELECT *
FROM flights
WHERE ORIGIN = 'AUS';")
ausflights <- dbFetch(res, -1)
dbClearResult(res)

res <- dbSendQuery(conn = dcon, "
SELECT *
FROM flights
WHERE ORIGIN = 'DFW';")
dfwFlights <- dbFetch(res, -1)
dbClearResult(res)

res <- dbSendQuery(conn = dcon, "
SELECT *
FROM flights
WHERE ORIGIN = 'DAL';")
dalFlights <- dbFetch(res, -1)
dbClearResult(res)

# IAH
n <- length(sort(table(iahFlights$DEST)))
top20 <- data.frame(sort(table(iahFlights$DEST))[(n -20):n]) 
top20names <- as.vector(top20$Var1)
top20data <- iahFlights[iahFlights$DEST %in% top20names, ]
p1 <- ggplot() + 
  geom_bar(data=top20data, aes(DEST), color="black", fill="lightblue") + 
  theme(axis.text.x=element_text(angle=90, hjust=1, size=9)) +
  ylab("Number of Flights") + 
  xlab("Destination") +
  ggtitle("Top 20 Destinations from IAH")

# AUS
n <- length(sort(table(ausflights$DEST)))
top20 <- data.frame(sort(table(ausflights$DEST))[(n -20):n]) 
top20names <- as.vector(top20$Var1)
top20data <- ausflights[ausflights$DEST %in% top20names, ]
p2 <- ggplot() + 
  geom_bar(data=top20data, aes(DEST), color="black", fill="pink") + 
  theme(axis.text.x=element_text(angle=90, hjust=1, size=9)) +
  ylab("Number of Flights") + 
  xlab("Destination") +
  ggtitle("Top 20 Destinations from AUS")

# DFW
n <- length(sort(table(dfwFlights$DEST)))
top20 <- data.frame(sort(table(dfwFlights$DEST))[(n -20):n]) 
top20names <- as.vector(top20$Var1)
top20data <- dfwFlights[dfwFlights$DEST %in% top20names, ]
p3 <- ggplot() + 
  geom_bar(data=top20data, aes(DEST), color="black", fill="lightgreen") + 
  theme(axis.text.x=element_text(angle=90, hjust=1, size=9)) +
  ylab("Number of Flights") + 
  xlab("Destination") +
  ggtitle("Top 20 Destinations from DFW")

# DAL
n <- length(sort(table(dalFlights$DEST)))
top20 <- data.frame(sort(table(dalFlights$DEST))[(n -20):n]) 
top20names <- as.vector(top20$Var1)
top20data <- dalFlights[dalFlights$DEST %in% top20names, ]
p4 <- ggplot() + 
  geom_bar(data=top20data, aes(DEST), color="black", fill="purple") + 
  theme(axis.text.x=element_text(angle=90, hjust=1, size=9)) +
  ylab("Number of Flights") + 
  xlab("Destination") +
  ggtitle("Top 20 Destinations from DAL")

grid.arrange(p1, p2, p3, p4, nrow = 2)
```

## IAH Flight and Passenger Data in 2018
```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE}
top10names <- c("ATL", "CLT", "DEN", "DFW", "DTW", "EWR", "LGA", "MSP", "ORD", "SFO")

# Count number of ppl that go to each airport from IAH 
res <- dbSendQuery(conn = dcon, "
SELECT DEST as dest, MONTH as month, SUM(PASSENGERS) as passenger_count
FROM passengers
WHERE ORIGIN = 'IAH'
GROUP BY DEST, MONTH;")
iahPassengers_total <- dbFetch(res, -1)
iahPassengers = iahPassengers_total[iahPassengers_total$dest %in% top10names,]
dbClearResult(res)

# Get count of number of flights out of IAH to each DEST
res <- dbSendQuery(conn = dcon, "
SELECT DEST as dest, MONTH as month, COUNT(*) as flight_count, DISTANCE as distance
FROM (SELECT DISTINCT YEAR, MONTH, DAY_OF_MONTH, DAY_OF_WEEK, TAIL_NUM, ORIGIN, DEST, DEP_TIME, DISTANCE
FROM flights)
WHERE ORIGIN = 'IAH' and YEAR = 2018
GROUP BY DEST, MONTH;")
iahFlightCount <- dbFetch(res, -1)
dbClearResult(res)
top10FlightCount = iahFlightCount[iahFlightCount$dest %in% top10names,]

# Get average rating from passengers
res <- dbSendQuery(conn = dcon, "
SELECT airport_code as dest, airport_name, AVG(overall_rating) as average_rating, AVG(clipped_sentiment) as review_rating
FROM sentiment
GROUP BY airport_name;")
raw_reviews <- dbFetch(res, -1)
dbClearResult(res)
reviews = raw_reviews[raw_reviews$dest %in% top10names,]

join1 = merge(iahPassengers, top10FlightCount, by=c("dest", "month"))
alldata = data.frame(merge(join1, reviews, by="dest"))

# Data preparation for graphing 

# Get the max per month 
max_passengers = data.frame(alldata %>% group_by(month) %>% summarise(max = max(passenger_count)))
max_flights = data.frame(alldata %>% group_by(month) %>% summarise(max = max(flight_count)))

regularized_passengers = c() 
regularized_flights = c()

for (row in 1:nrow(alldata)) {
    max_flight_count = max_flights[max_flights$month == 2,]$max
    new_flight_count = alldata[row, "flight_count"]*6 / (max_flight_count)
    regularized_flights = c(regularized_flights, new_flight_count)
    
    max_passenger_count = max_passengers[max_passengers$month == 2,]$max
    new_passenger_count = alldata[row, "passenger_count"] / (max_passenger_count*15)
    regularized_passengers = c(regularized_passengers, new_passenger_count)
}

alldata$passenger_count_regularized = regularized_passengers
alldata$flight_count_regularized = regularized_flights

# Join all the data together 
total_flights = as.data.frame(alldata %>% 
  group_by(month) %>% 
  summarise(Flights = sum(flight_count)))

total_flights$month <- c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")
total_flights$month <- fct_relevel(total_flights$month, "Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")

num_flights <- ggplot(data = total_flights) + 
  aes(x=total_flights$month, y=total_flights$Flights, group = 1) + 
  geom_line(stat="identity", col = "royalblue1", lwd = 2) +
  geom_point(col = "royalblue1", size = 3) +
  ggtitle("Number of Flights Per Month Out of IAH in 2018") + 
  xlab("Month") + 
  ylab("Number of Flights")

# Join all the data together 
total_passengers = as.data.frame(alldata %>% 
  group_by(month) %>% 
  summarise(Passengers = sum(passenger_count)))

total_passengers$month <- c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")
total_passengers$month <- fct_relevel(total_passengers$month, "Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")

num_pass <- ggplot(data = total_passengers) + 
  aes(x=month, y=Passengers, group = 1) + 
  geom_line(stat="identity", col = "royalblue1", lwd = 2) + 
  geom_point(col = "royalblue1", size = 3) +
  ggtitle("Number of Passengers Per Month Out of IAH in 2018") + 
  xlab("Month") + 
  ylab("Number of Passengers")

grid.arrange(num_flights, num_pass, nrow = 2)

```

## Empty Seats for Flights Out of IAH
```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE}
res <- dbSendQuery(conn=dcon, "
SELECT MONTH, SUM(SEATS) as CAPACITY, SUM(PASSENGERS) as FILLED
FROM passengers 
where ORIGIN == 'IAH'
group by MONTH;
")
seats <- dbFetch(res, -1)
dbClearResult(res)
seats['EMPTY'] = seats$CAPACITY - seats$FILLED

seats$MONTH= c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")

seats$MONTH = fct_relevel(seats$MONTH,"Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")

usingGg <- ggplot(data=seats, aes(x=seats$MONTH, y=seats$EMPTY, group=1)) +
  geom_line(col = "indianred1", lwd = 2)+
  geom_point(col = "indianred1", size = 3) + labs(title = "Empty Seats per Month from IAH in 2018", x= "Month", y = "Number of Empty Seats")

usingGg
```

## Distribution of Airport Ratings

```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE}
res <- dbSendQuery(conn = dcon, "
SELECT *
FROM flights2018
WHERE ORIGIN = 'IAH' and year = 2018;")
iahFlights <- dbFetch(res, -1)
dbClearResult(res)

n <- length(sort(table(iahFlights$DEST)))
top20 <- data.frame(sort(table(iahFlights$DEST))[(n -9):n]) 
top20names <- as.vector(top20$Var1)
top10data <- iahFlights[iahFlights$DEST %in% top20names, ]

res <- dbSendQuery(conn = dcon, "
SELECT *
FROM sentiment;")
reviews <- dbFetch(res, -1)
dbClearResult(res)

top10 <- c("atlanta-hartsfield-airport", "newark-airport", "dallas-fort-worth-airport", "denver-airport",
           "san-francisco-airport", "charlotte-airport", "detroit-airport", "la-guardia-airport",
           "chicago-ohare-airport", "minneapolis-st-paul-airport")
top <- reviews[reviews$airport_name %in% top10, ]


ggplot() + 
  geom_bar(data=top, aes(x = overall_rating, fill = factor(airport_name))) + 
  theme(axis.text.x=element_text(hjust=1, size=9)) +
  xlab("Overall Ratings") +
  ylab("Count") + 
  labs(fill = "Airports") +
  ggtitle("Distribution of Ratings for Top 10 Airports Out of IAH in 2018") +
  scale_x_continuous(breaks=c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
```


## {.flexbox .vcenter}
<div class="centered">
  <font size="8">Modeling</font> 
</div>

## Sentiment Analysis

- Conducted sentiment analysis on the airport reviews
- Used synonyms we scraped from thesaurus.com for our sentiment data set in order to condense the reviews
- Used RSentiment package on these condensed reviews in order to determine if a review had a positive, neutral, or negative sentiment
- Compared our sentiment score to the average rating of the airport to analyze effectiveness of sentiment analysis

## Analyzing the Effectiveness of Sentiment Analysis

```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE}
res <- dbSendQuery(conn = dcon, "
SELECT airport_name as Airport, sum(match) as NumMatches, count(match) as TotalReviews
FROM sentiment
GROUP BY title;")
matches_by_airport <- dbFetch(res, -1)
dbClearResult(res)

texas_airports <- matches_by_airport[matches_by_airport$Airport == "austin-airport" | matches_by_airport$Airport == "dallas-fort-worth-airport" | matches_by_airport$Airport == "dallas-love-field-airport" | matches_by_airport$Airport == "houston-george-bush-intercontinental-airport" | matches_by_airport$Airport == "houston-hobby-airport" | matches_by_airport$Airport == "el-paso-airport" ,]

value <- texas_airports$TotalReviews
airport <- c(rep("AUS", texas_airports[1,3]), rep("DFW", texas_airports[2,3]), rep("DAL", texas_airports[3,3]),
             rep("ELP", texas_airports[4,3]), rep("IAH", texas_airports[5,3]), rep("HOU", texas_airports[6,3]))


Result  <- c(rep("Mismatch",5), rep("Match",3), rep("Mismatch",9), rep("Match",40),
            rep("Match",3), rep("Mismatch",1), rep("Match",2), rep("Mismatch",28), rep("Match",69),
            rep("Mismatch",2), rep("Match",2))
data <- data.frame(airport,Result)

ggplot(data, aes(fill=Result, x=airport)) + 
  geom_bar(position="fill") + 
  xlab("Texas Airports") + 
  ylab("Percentage of Reviews") + 
  ggtitle("Accuracy for Sentiment Analysis Across Texas Airport Data") + scale_fill_manual(values = c("darkgreen", "red"))
```


## Time Series Data
```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE}
df_for_plotting <- function(m, fcst) {
  # Make sure there is no y in fcst
  fcst$y <- NULL
  df <- m$history %>%
    dplyr::select(ds, y) %>%
    dplyr::full_join(fcst, by = "ds") %>%
    dplyr::arrange(ds)
  return(df)
}

seasonality_plot_df <- function(m, ds) {
  df_list <- list(ds = ds, cap = 1, floor = 0)
  for (name in names(m$extra_regressors)) {
    df_list[[name]] <- 0
  }
  # Activate all conditional seasonality columns
  for (name in names(m$seasonalities)) {
    condition.name = m$seasonalities[[name]]$condition.name
    if (!is.null(condition.name)) {
      df_list[[condition.name]] <- TRUE
    }
  }
  df <- as.data.frame(df_list)
  df <- setup_dataframe(m, df)$df
  return(df)
}

plot_weekly <- function(m, uncertainty = TRUE, weekly_start = 0, 
                        name = 'weekly') {
  # Compute weekly seasonality for a Sun-Sat sequence of dates.
  days <- seq(set_date('2017-01-01'), by='d', length.out=7) + as.difftime(
    weekly_start, units = "days")
  df.w <- seasonality_plot_df(m, days)
  seas <- predict_seasonal_components(m, df.w)
  seas$dow <- factor(weekdays(df.w$ds), levels=weekdays(df.w$ds))

  gg.weekly <- ggplot2::ggplot(
      seas, ggplot2::aes_string(x = 'dow', y = name, group = 1)) +
    ggplot2::geom_line(color = "#0072B2", na.rm = TRUE) +
    ggplot2::labs(x = "Day of week")
  if (uncertainty && m$uncertainty.samples) {
    gg.weekly <- gg.weekly +
      ggplot2::geom_ribbon(ggplot2::aes_string(ymin = paste0(name, '_lower'),
                                               ymax = paste0(name, '_upper')),
                           alpha = 0.2,
                           fill = "#0072B2",
                           na.rm = TRUE)
  }
  if (m$seasonalities[[name]]$mode == 'multiplicative') {
    gg.weekly <- (
      gg.weekly + ggplot2::scale_y_continuous(labels = scales::percent)
    )
  }
  return(gg.weekly)
}

plot.prophet <- function(x, fcst, uncertainty = TRUE, plot_cap = TRUE,
                         xlabel = 'ds', ylabel = 'y', ...) {
  df <- df_for_plotting(x, fcst)
  gg <- ggplot2::ggplot(df, ggplot2::aes(x = ds, y = y)) +
    ggplot2::labs(x = "Month and Year", y = "Number of Daily Flights") +
    ggplot2::ggtitle("Number of flights per day out of IAH")
  if (exists('cap', where = df) && plot_cap) {
    gg <- gg + ggplot2::geom_line(
      ggplot2::aes(y = cap), linetype = 'dashed', na.rm = TRUE)
  }
  if (x$logistic.floor && exists('floor', where = df) && plot_cap) {
    gg <- gg + ggplot2::geom_line(
      ggplot2::aes(y = floor), linetype = 'dashed', na.rm = TRUE)
  }
  if (uncertainty && x$uncertainty.samples && exists('yhat_lower', where = df)) {
    gg <- gg +
      ggplot2::geom_ribbon(ggplot2::aes(ymin = yhat_lower, ymax = yhat_upper),
                           alpha = 0.2,
                           fill = "#0072B2",
                           na.rm = TRUE)
  }
  gg <- gg +
    ggplot2::geom_point(na.rm=TRUE) +
    ggplot2::geom_line(ggplot2::aes(y = yhat), color = "#0072B2",
                       na.rm = TRUE) +
    ggplot2::theme(aspect.ratio = 3 / 5)
  return(gg)
}

plot_forecast_component <- function(
  m, fcst, name, uncertainty = TRUE, plot_cap = FALSE
) {
  gg.comp <- ggplot2::ggplot(
      fcst, ggplot2::aes_string(x = 'ds', y = name, group = 1)) +
    ggplot2::geom_line(color = "#0072B2", na.rm = TRUE)
  if (exists('cap', where = fcst) && plot_cap) {
    gg.comp <- gg.comp + ggplot2::geom_line(
      ggplot2::aes(y = cap), linetype = 'dashed', na.rm = TRUE)
  }
  if (exists('floor', where = fcst) && plot_cap) {
    gg.comp <- gg.comp + ggplot2::geom_line(
      ggplot2::aes(y = floor), linetype = 'dashed', na.rm = TRUE)
  }
  if (uncertainty && m$uncertainty.samples) {
    gg.comp <- gg.comp +
      ggplot2::geom_ribbon(
        ggplot2::aes_string(
          ymin = paste0(name, '_lower'), ymax = paste0(name, '_upper')
        ),
        alpha = 0.2,
        fill = "#0072B2",
        na.rm = TRUE)
  }
  if (name %in% m$component.modes$multiplicative) {
    gg.comp <- gg.comp + ggplot2::scale_y_continuous(labels = scales::percent)
  }
  return(gg.comp)
}

set_date <- function(ds = NULL, tz = "GMT") {
  if (length(ds) == 0) {
    return(NULL)
  }

  if (is.factor(ds)) {
    ds <- as.character(ds)
  }

  if (min(nchar(ds), na.rm=TRUE) < 12) {
    ds <- as.POSIXct(ds, format = "%Y-%m-%d", tz = tz)
  } else {
    ds <- as.POSIXct(ds, format = "%Y-%m-%d %H:%M:%S", tz = tz)
  }
  attr(ds, "tzone") <- tz
  return(ds)
}

setup_dataframe <- function(m, df, initialize_scales = FALSE) {
  if (exists('y', where=df)) {
    df$y <- as.numeric(df$y)
  }
  if (any(is.infinite(df$y))) {
    stop("Found infinity in column y.")
  }
  df$ds <- set_date(df$ds)
  if (anyNA(df$ds)) {
    stop(paste('Unable to parse date format in column ds. Convert to date ',
               'format (%Y-%m-%d or %Y-%m-%d %H:%M:%S) and check that there',
               'are no NAs.'))
  }
  for (name in names(m$extra_regressors)) {
    if (!(name %in% colnames(df))) {
      stop('Regressor "', name, '" missing from dataframe')
    }
    df[[name]] <- as.numeric(df[[name]])
    if (anyNA(df[[name]])) {
      stop('Found NaN in column ', name)
    }
  }
  for (name in names(m$seasonalities)) {
    condition.name = m$seasonalities[[name]]$condition.name
    if (!is.null(condition.name)) {
      if (!(condition.name %in% colnames(df))) {
        stop('Condition "', name, '" missing from dataframe')
      }
      if(!all(df[[condition.name]] %in% c(FALSE,TRUE))) {
        stop('Found non-boolean in column ', name)
      }
      df[[condition.name]] <- as.logical(df[[condition.name]])
    }
  }
  
  df <- df %>%
    dplyr::arrange(ds)

  m <- initialize_scales_fn(m, initialize_scales, df)

  if (m$logistic.floor) {
    if (!('floor' %in% colnames(df))) {
      stop("Expected column 'floor'.")
    }
  } else {
    df$floor <- 0
  }

  if (m$growth == 'logistic') {
    if (!(exists('cap', where=df))) {
      stop('Capacities must be supplied for logistic growth.')
    }
    if (any(df$cap <= df$floor)) {
      stop('cap must be greater than floor (which defaults to 0).')
    }
    df <- df %>%
      dplyr::mutate(cap_scaled = (cap - floor) / m$y.scale)
  }

  df$t <- time_diff(df$ds, m$start, "secs") / m$t.scale
  if (exists('y', where=df)) {
    df$y_scaled <- (df$y - df$floor) / m$y.scale
  }

  for (name in names(m$extra_regressors)) {
    props <- m$extra_regressors[[name]]
    df[[name]] <- (df[[name]] - props$mu) / props$std
  }
  return(list("m" = m, "df" = df))
}

initialize_scales_fn <- function(m, initialize_scales, df) {
  if (!initialize_scales) {
    return(m)
  }
  if ((m$growth == 'logistic') && ('floor' %in% colnames(df))) {
    m$logistic.floor <- TRUE
    floor <- df$floor
  } else {
    floor <- 0
  }
  m$y.scale <- max(abs(df$y - floor))
  if (m$y.scale == 0) {
    m$y.scale <- 1
  }
  m$start <- min(df$ds)
  m$t.scale <- time_diff(max(df$ds), m$start, "secs")
  for (name in names(m$extra_regressors)) {
    standardize <- m$extra_regressors[[name]]$standardize
    n.vals <- length(unique(df[[name]]))
    if (n.vals < 2) {
      standardize <- FALSE
    }
    if (standardize == 'auto') {
      if (n.vals == 2 && all(sort(unique(df[[name]])) == c(0, 1))) {
        # Don't standardize binary variables
        standardize <- FALSE
      } else {
        standardize <- TRUE
      }
    }
    if (standardize) {
      mu <- mean(df[[name]])
      std <- stats::sd(df[[name]])
      m$extra_regressors[[name]]$mu <- mu
      m$extra_regressors[[name]]$std <- std
    }
  }
  return(m)
}

time_diff <- function(ds1, ds2, units = "days") {
  return(as.numeric(difftime(ds1, ds2, units = units)))
}

predict_seasonal_components <- function(m, df) {
  out <- make_all_seasonality_features(m, df)
  m <- out$m
  seasonal.features <- out$seasonal.features
  component.cols <- out$component.cols
  if (m$uncertainty.samples){
    lower.p <- (1 - m$interval.width)/2
    upper.p <- (1 + m$interval.width)/2
  }

  X <- as.matrix(seasonal.features)
  component.predictions <- data.frame(matrix(ncol = 0, nrow = nrow(X)))
  for (component in colnames(component.cols)) {
    beta.c <- t(m$params$beta) * component.cols[[component]]

    comp <- X %*% beta.c
    if (component %in% m$component.modes$additive) {
      comp <- comp * m$y.scale
    }
    component.predictions[[component]] <- rowMeans(comp, na.rm = TRUE)
    if (m$uncertainty.samples){
      component.predictions[[paste0(component, '_lower')]] <- apply(
        comp, 1, stats::quantile, lower.p, na.rm = TRUE)
      component.predictions[[paste0(component, '_upper')]] <- apply(
        comp, 1, stats::quantile, upper.p, na.rm = TRUE)
    }
  }
  return(component.predictions)
}

make_seasonality_features <- function(dates, period, series.order, prefix) {
  features <- fourier_series(dates, period, series.order)
  colnames(features) <- paste(prefix, 1:ncol(features), sep = '_delim_')
  return(data.frame(features))
}

make_all_seasonality_features <- function(m, df) {
  seasonal.features <- data.frame(row.names = 1:nrow(df))
  prior.scales <- c()
  modes <- list(additive = c(), multiplicative = c())

  # Seasonality features
  for (name in names(m$seasonalities)) {
    props <- m$seasonalities[[name]]
    features <- make_seasonality_features(
      df$ds, props$period, props$fourier.order, name)
    if (!is.null(props$condition.name)) {
      features[!df[[props$condition.name]],] <- 0
    }
    seasonal.features <- cbind(seasonal.features, features)
    prior.scales <- c(prior.scales,
                      props$prior.scale * rep(1, ncol(features)))
    modes[[props$mode]] <- c(modes[[props$mode]], name)
  }

  # Holiday features
  holidays <- construct_holiday_dataframe(m, df$ds)
  if (nrow(holidays) > 0) {
    out <- make_holiday_features(m, df$ds, holidays)
    m <- out$m
    seasonal.features <- cbind(seasonal.features, out$holiday.features)
    prior.scales <- c(prior.scales, out$prior.scales)
    modes[[m$seasonality.mode]] <- c(
      modes[[m$seasonality.mode]], out$holiday.names
    )
  }

  # Additional regressors
  for (name in names(m$extra_regressors)) {
    props <- m$extra_regressors[[name]]
    seasonal.features[[name]] <- df[[name]]
    prior.scales <- c(prior.scales, props$prior.scale)
    modes[[props$mode]] <- c(modes[[props$mode]], name)
  }

  # Dummy to prevent empty X
  if (ncol(seasonal.features) == 0) {
    seasonal.features <- data.frame(zeros = rep(0, nrow(df)))
    prior.scales <- c(1.)
  }

  components.list <- regressor_column_matrix(m, seasonal.features, modes)
  return(list(m = m,
              seasonal.features = seasonal.features,
              prior.scales = prior.scales,
              component.cols = components.list$component.cols,
              modes = components.list$modes))
}

fourier_series <- function(dates, period, series.order) {
  t <- time_diff(dates, set_date('1970-01-01 00:00:00'))
  features <- matrix(0, length(t), 2 * series.order)
  for (i in 1:series.order) {
    x <- as.numeric(2 * i * pi * t / period)
    features[, i * 2 - 1] <- sin(x)
    features[, i * 2] <- cos(x)
  }
  return(features)
}

construct_holiday_dataframe <- function(m, dates) {
  all.holidays <- data.frame()
  if (!is.null(m$holidays)){
    all.holidays <- m$holidays
  }
  if (!is.null(m$country_holidays)) {
    year.list <- as.numeric(unique(format(dates, "%Y")))
    country.holidays.df <- make_holidays_df(year.list, m$country_holidays)
    all.holidays <- suppressWarnings(dplyr::bind_rows(all.holidays, country.holidays.df))
  }
  # If the model has already been fit with a certain set of holidays,
  # make sure we are using those same ones.
  if (!is.null(m$train.holiday.names)) {
    row.to.keep <- which(all.holidays$holiday %in% m$train.holiday.names)
    all.holidays <- all.holidays[row.to.keep,]
    holidays.to.add <- data.frame(
      holiday=setdiff(m$train.holiday.names, all.holidays$holiday)
    )
    all.holidays <- suppressWarnings(dplyr::bind_rows(all.holidays, holidays.to.add))
  }
  return(all.holidays)
}

regressor_column_matrix <- function(m, seasonal.features, modes) {
  components <- dplyr::data_frame(component = colnames(seasonal.features)) %>%
    dplyr::mutate(col = seq_len(dplyr::n())) %>%
    tidyr::separate(component, c('component', 'part'), sep = "_delim_",
                    extra = "merge", fill = "right") %>%
    dplyr::select(col, component)
  # Add total for holidays
  if(!is.null(m$train.holiday.names)){
    components <- add_group_component(
      components, 'holidays', unique(m$train.holiday.names))
  }
  # Add totals for additive and multiplicative components, and regressors
  for (mode in c('additive', 'multiplicative')) {
    components <- add_group_component(
      components, paste0(mode, '_terms'), modes[[mode]])
    regressors_by_mode <- c()
    for (name in names(m$extra_regressors)) {
      if (m$extra_regressors[[name]]$mode == mode) {
        regressors_by_mode <- c(regressors_by_mode, name)
      }
    }
    components <- add_group_component(
      components, paste0('extra_regressors_', mode), regressors_by_mode)
    # Add combination components to modes
    modes[[mode]] <- c(modes[[mode]], paste0(mode, '_terms'))
    modes[[mode]] <- c(modes[[mode]], paste0('extra_regressors_', mode))
  }
  # After all of the additive/multiplicative groups have been added,
  modes[[m$seasonality.mode]] <- c(modes[[m$seasonality.mode]], 'holidays')
  # Convert to a binary matrix
  component.cols <- as.data.frame.matrix(
    table(components$col, components$component)
  )
  component.cols <- (
    component.cols[order(as.numeric(row.names(component.cols))), ,
                   drop = FALSE]
  )
  # Add columns for additive and multiplicative terms, if missing
  for (name in c('additive_terms', 'multiplicative_terms')) {
    if (!(name %in% colnames(component.cols))) {
      component.cols[[name]] <- 0
    }
  }
  # Remove the placeholder
  components <- dplyr::filter(components, component != 'zeros')
  # Validation
  if (
    max(component.cols$additive_terms
    + component.cols$multiplicative_terms) > 1
  ) {
    stop('A bug occurred in seasonal components.')
  }
  # Compare to training, if set.
  if (!is.null(m$train.component.cols)) {
    component.cols <- component.cols[, colnames(m$train.component.cols)]
    if (!all(component.cols == m$train.component.cols)) {
      stop('A bug occurred in constructing regressors.')
    }
  }
  return(list(component.cols = component.cols, modes = modes))
}

add_group_component <- function(components, name, group) {
  new_comp <- components[(components$component %in% group), ]
  group_cols <- unique(new_comp$col)
  if (length(group_cols) > 0) {
    new_comp <- data.frame(col=group_cols, component=name)
    components <- rbind(components, new_comp)
  }
  return(components)
}
```

```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE}
res <- dbSendQuery(conn=dcon, "
SELECT ORIGIN, YEAR, MONTH, DAY_OF_MONTH, count(*) as count
FROM (SELECT DISTINCT YEAR, MONTH, DAY_OF_MONTH, DAY_OF_WEEK, TAIL_NUM, ORIGIN, DEST, DEP_TIME
FROM flights) as dr
where dr.ORIGIN == 'IAH'
group by YEAR, MONTH, DAY_OF_MONTH;
")
df4b <- dbFetch(res, -1)
dbClearResult(res)

times <- as.POSIXct(24*3600 * 0:1460, origin = '2015-01-01', tz = "GMT")
df <- data.frame("ds" = times, "y" = df4b$count[0:1461])
ggplot2::ggplot(df, ggplot2::aes(x = ds, y = y)) +
ggplot2::labs(x = "Date", y = "Number of Flights out of IAH") +
ggplot2::ggtitle("Flights per day out of IAH from 2015 to 2019") +
ggplot2::geom_point(na.rm=TRUE) +
ggplot2::theme(aspect.ratio = 3 / 5)
```

## Daily Time Series Model for Flights Out of IAH 2015-2018
```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE}
m <- prophet()
m <- add_country_holidays(m, country_name = 'US')
m <- fit.prophet(m, df)
future <- make_future_dataframe(m, periods = 1)
forecast <- predict(m, future)
df.cv <- cross_validation(m, initial=1400, period = 1, horizon=60, units = 'days')
df.p <- performance_metrics(df.cv)
#plot(m, forecast)
#prophet_plot_components(m, forecast)
dyplot.prophet(m, forecast)
```

## Time Series Model Components
```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE}
components <- prophet_plot_components(m, forecast, render_plot=FALSE)
a <- components[[1]] + labs(x = "Year", y="") + ggtitle("Trend Component")
b <- components[[2]] + labs(x = "Year", y = "") + ggtitle("Holiday Component")
c <- components[[3]] + labs(x = "Day of the Week", y="") + ggtitle("Weekly Seasonal Component")
d <- components[[4]] + labs(x = "Month and Day", y="") + ggtitle("Yearly Seasonal Component")
grid.arrange(a,b,c,d,nrow=4)
```

## Time Series Forecasting on Test Data
```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE}
ggplot2::ggplot(df.cv, ggplot2::aes(x = ds, y = y)) +
ggplot2::labs(x = "Month and Day", y = "Number of Flights") +
ggplot2::ggtitle("Forecasted Number of Flights per Day Out of IAH vs. Actual") +
ggplot2::geom_point(na.rm=TRUE) +
ggplot2::geom_line(ggplot2::aes(y = yhat), color = "#0072B2",
                       na.rm = TRUE) +
    ggplot2::theme(aspect.ratio = 3 / 5)

train_rmse <- mean(((m$history$y - forecast$yhat[0:length(m$history$y)])**2)**.5)
train_mae <- mean(abs(m$history$y - forecast$yhat[0:length(m$history$y)]))
train_mape <- mean(abs(m$history$y - forecast$yhat[0:length(m$history$y)])/m$history$y)
train_mean <- mean(m$history$y)

test_rmse <- mean(df.p$rmse)
test_mae <- mean(df.p$mae)
test_mape <- mean(df.p$mape)
test_mean <- mean(df.cv$y)
```

## Model Error
Type         MAE          MAPE  
-------     -------      ----------  
     Train      17.53556     0.04550617     
     Test      19.77747     0.04323118

## {.flexbox .vcenter}
<div class="centered">
  <font size="8">Killer Plots</font> 
</div>

## Killer Plot #1

```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE}
plot_nodes <- function(radius, rating, X, Y, sentiment, idx) {
  for (idx in 1:10){ 
    # Cutoff threshold is 5 because ratings can range from 1 to 10 
    fillColor = ifelse(rating[idx + ((idx-1)*10)] > 5.0, "green", "red")
    # Cutoff threshold is 0.0 because ratings can range from -1 to 1 
    outlineColor = ifelse(sentiment[idx + ((idx-1)*10)] > 0.2, "red", "green") 
    grid.circle(x = unit(X[idx], "npc"), y = unit(Y[idx], "npc"), r = unit(radius[idx], "npc"),
                gp = gpar(fill = fillColor, col = outlineColor, lwd = 3))
  }
}

label_nodes <- function(labels, X, Y) {
  for (i in 1:10){
    grid.text(labels[i], x = unit(X[i], "npc"), y = unit(Y[i], "npc"), gp = gpar(fontsize = 7))
  }
}

plot_luggage <- function() {
  grid.rect(x = unit(0.5, "npc"), y = unit(0.40, "npc"), width = unit(0.80, "npc"), 
            height = unit(0.70, "npc"), gp = gpar(lwd = 4))
  grid.lines(x = unit(c(0.25, 0.25), "npc"),y = unit(c(0.75, 0.92), "npc"), gp = gpar(lwd = 4))
  grid.lines(x = unit(c(0.75, 0.75), "npc"),y = unit(c(0.75, 0.92), "npc"), gp = gpar(lwd = 4))
  grid.lines(x = unit(c(0.25, 0.75), "npc"),y = unit(c(0.92, 0.92), "npc"), gp = gpar(lwd = 4))
  grid.lines(x = unit(c(0.30, 0.30), "npc"),y = unit(c(0.75, 0.85), "npc"), gp = gpar(lwd = 4))
  grid.lines(x = unit(c(0.70, 0.70), "npc"),y = unit(c(0.75, 0.85), "npc"), gp = gpar(lwd = 4))
  grid.lines(x = unit(c(0.30, 0.70), "npc"),y = unit(c(0.85, 0.85), "npc"), gp = gpar(lwd = 4))
  grid.text("Top 10 Airport Destinations from IAH 2018 Analysis", x = unit(0.50, "npc"), 
            y = unit(0.885, "npc"),gp = gpar(fontsize = 9, fontface = 'bold'))
}

plot_legend <- function() {
  grid.lines(x = unit(c(0.70, 0.85), "npc"), y = unit(c(0.80, 0.70), "npc"), gp = gpar(lwd = 4))
  grid.rect(x = unit(0.83, "npc"), y = unit(0.60, "npc"), width = unit(0.305, "npc"), 
            height = unit(0.26, "npc"), gp = gpar(lwd = 4))
  grid.text("Legend:", x = unit(0.73, "npc"), y = unit(0.71, "npc"), 
            gp = gpar(fontsize = 10, fontface = 'bold'))
  grid.text("Size of Node = Passengers per month", x = unit(0.695, "npc"), 
            y = unit(0.68, "npc"),gp = gpar(fontsize = 8), just = "left")
  grid.text("Red Node = Low rated airport", x = unit(0.695, "npc"), 
            y = unit(0.65, "npc"),gp = gpar(fontsize = 8), just = "left")
  grid.text("Green Node = High rated airport", x = unit(0.695, "npc"), 
            y = unit(0.62, "npc"),gp = gpar(fontsize = 8), just = "left")
  grid.text("Red Border = Negative airport reviews", x = unit(0.695, "npc"), 
            y = unit(0.59, "npc"),gp = gpar(fontsize = 8), just = "left")
  grid.text("Green Border = Positive airport reviews", x = unit(0.695, "npc"), 
            y = unit(0.56, "npc"),gp = gpar(fontsize = 8), just = "left")
  grid.text("Edge Length = Distance to Airport", x = unit(0.695, "npc"), 
            y = unit(0.53, "npc"),gp = gpar(fontsize = 8), just = "left")
  grid.text("Width of Edge = Flights per month", x = unit(0.695, "npc"), 
            y = unit(0.50, "npc"),gp = gpar(fontsize = 8), just = "left")
}

plot_edges <- function(U, V, weights) {
  for (i in 1:10){
    grid.lines(x = unit(c(0.4, U[i]), "npc"), y = unit(c(0.12, V[i]), "npc"), gp = gpar(lwd = weights[i]))
  }
}

my.grid.plot <- function(data, month){
  grid.newpage()
  grid.layout(1,2)
  top.vp <- viewport(width = 1.0, height = 1.0)
  pushViewport(top.vp)
  
  plot_luggage()
  plot_legend()
  
  # Create IAH Node 
  grid.circle(x = unit(0.4, "npc"), y = unit(0.12, "npc"), r = unit(0.03, "npc"), gp = gpar(fill = "black"))
  grid.text("IAH", x=unit(0.4, "npc"), y=unit(0.075, "npc"), gp=gpar(fontsize=8))
  
  # Create Edges 
  #     689,  912   862   224   1075  1400  1416  1034  925   1635
  X = c(0.18, 0.20, 0.33, 0.30, 0.43, 0.53, 0.63, 0.68, 0.63, 0.75)
  Y = c(0.38, 0.53, 0.45, 0.13, 0.55, 0.66, 0.61, 0.43, 0.23, 0.15)
  weights = data[data$month == month,]$flight_count_regularized
  plot_edges(X, Y, weights) 
  
  # Create Nodes 
  radius = data[data$month == month,]$passenger_count_regularized
  rating = data$average_rating 
  sentiment = data$review_rating
  labels = c("ATL", "CLT", "DEN", "DFW", "DTW", "EWR", "LGA", "MSP", "ORD", "SFO")  
  labels_X = c(0.18, 0.20, 0.33,  0.22,  0.43,  0.54,  0.63,  0.68,  0.705,  0.81)
  labels_Y = c(0.46, 0.60, 0.56,  0.13,  0.61,  0.58,  0.55,  0.38,  0.23,  0.15)
  plot_nodes(radius, rating, X, Y, sentiment)
  label_nodes(labels, labels_X, labels_Y)
}

# Define UI for application that draws a histogram
ui <- fluidPage(
   # Application title
   titlePanel("Top 10 Airport Destinations from IAH 2018 Analysis"),
   # Sidebar with a slider input for number of bins 
    sidebarPanel(
      radioButtons("month",
                   label = "Select Month:",
                   choices = list("January"=1,"February"=2,"March"=3,
                                  "April"=4, "May"=5, "June"=6, 
                                  "July"=7, "August"=8, "September"=9, 
                                  "October"=10, "November"=11, "December"=12),
                   selected = 1)
    ),
      # Show a plot of the generated distribution
      mainPanel(
         plotOutput("killerPlot", width="510px", height="400px")
      )
   )

# Define server logic required to draw a histogram
server <- function(input, output) {
  output$killerPlot <- renderPlot({
    # generate killer plot based on input$month from ui.R
    my.grid.plot(alldata, input$month)
  })
}

# Run the application 
shinyApp(ui = ui, server = server)

#my.grid.plot(alldata, 1)
```

## Killer Plot #2

```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE, eval=FALSE}
my.grid.plot <- function(vals) {
  grid.newpage()
  grid.layout(1,2)
  top.vp <- viewport(width = 0.8, height = 0.8)
  pushViewport(top.vp)
  grid.lines(x = unit(c(0, 0.9), "npc"),y = unit(c(0.90, 0.90), "npc"))
  grid.lines(x = unit(c(0, 0.9), "npc"),y = unit(c(0.10, 0.10), "npc"))
  grid.lines(x = unit(c(0.9, 1.1), "npc"),y = unit(c(0.90, 0.50), "npc"))
  grid.lines(x = unit(c(0.9, 1.1), "npc"),y = unit(c(0.1, 0.50), "npc"))
  grid.curve(0,0.90,-0.1,0.50,default.units = "npc", curvature = 0.5)
  grid.curve(-0.1,0.50,0,0.10,default.units = "npc", curvature = 0.5)
  grid.curve(0.9,0.90,1.1,0.50,default.units = "npc", curvature = -0.25)
  grid.curve(0.9,0.1,1.1,0.5,default.units = "npc", curvature = 0.25)
  grid.lines(x = unit(c(0.35, 0.35), "npc"),y = unit(c(0.9, 1.1), "npc"))
  grid.lines(x = unit(c(0.35, 0.35), "npc"),y = unit(c(0.1, -1), "npc"))
  grid.lines(x = unit(c(0.7, 0.39), "npc"),y = unit(c(0.9, 1.7), "npc"))
  grid.lines(x = unit(c(0.7, 0.39), "npc"),y = unit(c(0.1, -1.3), "npc"))
  
for (x in 1:5){
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.85, 0.85), "npc"))
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.72, 0.72), "npc"))
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.05 + 0.18*(x-1)), "npc"),y = unit(c(0.72, 0.85), "npc"))
  grid.lines(x = unit(c(0.15 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.72, 0.85), "npc"))
  
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.70, 0.70), "npc"))
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.57, 0.57), "npc"))
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.05 + 0.18*(x-1)), "npc"),y = unit(c(0.57, 0.70), "npc"))
  grid.lines(x = unit(c(0.15 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.57, 0.70), "npc"))
  
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.85, 0.85), "npc"))
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.72, 0.72), "npc"))
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.05 + 0.18*(x-1)), "npc"),y = unit(c(0.72, 0.85), "npc"))
  grid.lines(x = unit(c(0.15 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.72, 0.85), "npc"))
  
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.43, 0.43), "npc"))
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.30, 0.30), "npc"))
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.05 + 0.18*(x-1)), "npc"),y = unit(c(0.30, 0.43), "npc"))
  grid.lines(x = unit(c(0.15 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.30, 0.43), "npc"))
  
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.28, 0.28), "npc"))
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.15, 0.15), "npc"))
  grid.lines(x = unit(c(0.05 + 0.18*(x-1), 0.05 + 0.18*(x-1)), "npc"),y = unit(c(0.15, 0.28), "npc"))
  grid.lines(x = unit(c(0.15 + 0.18*(x-1), 0.15 + 0.18*(x-1)), "npc"),y = unit(c(0.15, 0.28), "npc"))
}

  grid.text("AIR405", x=.5,y=0.03)
  grid.text("AIR405", x=.5,y=0.97)
}
```

```{r, echo=FALSE, message = FALSE, error = FALSE, warning=FALSE, fig.height=5.5, fig.width=7.5}

res <- dbSendQuery(conn = dcon, "
                   SELECT UNIQUE_CARRIER_NAME, count(*) as count, sum(PASSENGERS) as passenger_count, sum(SEATS) as capacity
                   FROM passengers
                   WHERE ORIGIN = 'IAH'
                   GROUP BY UNIQUE_CARRIER_NAME
                   ORDER BY passenger_count;")
airlines <- dbFetch(res, -1)
dbClearResult(res)
total_passengers_carried <- sum(airlines$passenger_count)
airlines$percent = airlines$passenger_count / total_passengers_carried

plane<-readJPEG("C:/Users/bcard/Documents/SavedStuff/Stat405/Plane.jpg")
airlineu<-readJPEG("C:/Users/bcard/Documents/SavedStuff/Stat405/United_Air_Lines_Inc..jpeg")
#now open a plot window with coordinates
plot(1:10,ty="n",xaxt='n',yaxt='n', axes=FALSE, ylab = "", xlab = "Proportion of Passengers carried out of IAH by Airline")

#specify the position of the image through bottom-left and top-right coords
rasterImage(plane,0,1,10.5,10)

for (x in 1:5){
rasterImage(airlineu,1.57 + (x-1)*1.465 , 3.05 , 2.4 + (x-1)*1.465 , 3.9)
rasterImage(airlineu,1.57 + (x-1)*1.465 , 4.05 , 2.4 + (x-1)*1.465 , 4.9)  
}

airlinem<-readJPEG("C:/Users/bcard/Documents/SavedStuff/Stat405/Mesa_Airlines_Inc..jpeg")
rasterImage(airlinem,1.57 , 5.85 , 2.4 , 6.7)
rasterImage(airlinem,1.57 + (1)*1.465 , 5.85 , 2.4 + (1)*1.465 , 6.75)
rasterImage(airlinem,1.57 + (2)*1.465 , 5.85 , 2.4 + (2)*1.465 , 6.75)

airlinee<-readJPEG("C:/Users/bcard/Documents/SavedStuff/Stat405/ExpressJet_Airlines_LLC.jpg")
rasterImage(airlinee,1.57 , 6.85 , 2.4 , 7.75)
rasterImage(airlinee,1.57 + (1)*1.465 , 6.85 , 2.4 + (1)*1.465 , 7.75)

airlines<-readJPEG("C:/Users/bcard/Documents/SavedStuff/Stat405/Spirit_Air_lines.jpeg")
rasterImage(airlines,1.57 + (2)*1.465 , 6.85 , 2.4 + (2)*1.465 , 7.75)
rasterImage(airlines,1.57 + (3)*1.465 , 6.85 , 2.4 + (3)*1.465 , 7.75)

airlineaa<-readJPEG("C:/Users/bcard/Documents/SavedStuff/Stat405/American_Airlines_Inc..jpg")
rasterImage(airlineaa,1.57 + (3)*1.465 , 5.85 , 2.4 + (3)*1.465 , 6.75)

airliner<-readJPEG("C:/Users/bcard/Documents/SavedStuff/Stat405/Republic_Airline.jpeg")
rasterImage(airliner,1.57 + (4)*1.465 , 5.85 , 2.4 + (4)*1.465 , 6.75)

```

## {.flexbox .vcenter}
<div class="centered">
  <font size="8">Conclusion</font> 
  
</div>

## IAH Quantitative Metrics 

- Most popular airlines: United, Mesa, Spirit, American Airlines, Express, Republic
- Top destination based on flights: ATL, CLT, DEN, DFW, DTW, EWR, LGA, MSP, ORD, SFO

## IAH Qualitative Metrics 

- Analyzed airport quality through sentiment analysis 
- Visualized inefficiencies that airlines in IAH face

## IAH Time-Based Metrics 
* Reinforced assumptions on seasonal effects on flight patterns
  + Summer months have the most number of flights and passengers 
* Analyzed flight patterns over time through time series models
  + Visually represented flight pattern changes through killer plot
  + And predicted future flight patterns with minimal error 

## {.flexbox .vcenter}
<div class="centered">
  <font size="8">Thanks!</font> 
  
  Any questions? 
</div>

